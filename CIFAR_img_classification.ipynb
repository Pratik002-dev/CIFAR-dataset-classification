{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZktA3hzjX_l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Input,Conv2D,Dense,Flatten,Dropout\n",
        "from keras.layers import GlobalMaxPooling2D,MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02fn30_ukOqa",
        "outputId": "905d0801-fb32-47a6-a74c-72c64c923a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH=32\n",
        "IMG_HEIGHT=32\n",
        "IMG_CHANNELS=3\n",
        "\n",
        "#The dataset  is now imported from keras datasets.\n",
        "#Now we have to load and distribute the data to train and test set using load_data()\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data() #trainX,testX=Training & testing data, trainY,testY=Training and testing target data\n",
        "print(trainX.shape,trainY.shape,testX.shape,testY.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S9dF75nMJIB"
      },
      "outputs": [],
      "source": [
        "trainX1=normalize(trainX,axis=1)\n",
        "testX1=normalize(testX,axis=1)\n",
        "\n",
        "trainY1= to_categorical(trainY)\n",
        "testY1= to_categorical(testY)\n",
        "\n",
        "inputs=tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))\n",
        "c1= tf.keras.layers.Conv2D(16,9 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQc7WvfKMJw8"
      },
      "outputs": [],
      "source": [
        "#Before sending the input data through neural network,we need to process it first by reducing the pixel values\n",
        "trainX,testX=trainX/255.0,testX/255.0\n",
        "\n",
        "#Now we flatten(put the dataset array matrix in one row vector form) the label values using flatten() function\n",
        "trainY,testY=trainY.flatten(),testY.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWfUEuQbQWF-",
        "outputId": "042f5ff3-1fb8-4d1b-a4db-bd3725db86d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of classes: 10\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,410,282\n",
            "Trainable params: 8,410,154\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Now, we build and train the model input layer using Convolution layer, \n",
        "#which consists of Conv2D layer,pooling layer,normalisation methods \n",
        "#and activation functions ReLU.\n",
        "\n",
        "i=Input(shape=trainX[0].shape)\n",
        "x=Conv2D(32,(3,3),activation='relu',padding='same')(i) #Padding function used to keep the input and output layer size same\n",
        "x=BatchNormalization()(x) #Used to normalize the output of previous layers\n",
        "\n",
        "x=Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "x=MaxPooling2D((2,2))(x) #MaxPooling layer reduces the dimensionality of the image by taking the max of a group of pixel matrix values\n",
        "\n",
        "x=Flatten()(x) #After pooling operation, we need to convert the 2D array matrix to a single row vector using flatten() function\n",
        "\n",
        "x=Dropout(0.2)(x) #This layer sets the input layer neuron values to zero,preventing overfitting of model\n",
        "\n",
        "#Hidden layer\n",
        "x=Dense (1024,activation='relu')(x)\n",
        "x=Dropout(0.2)(x)\n",
        "\n",
        "#No.of classes(k)\n",
        "k=len(set(trainY))\n",
        "print(\"No. of classes:\",k)\n",
        "#Passing input through last hidden layer, the output layer, which will give the final output\n",
        "x=Dense(k,activation='softmax')(x) #Softmax function assigns probabilities to each output class in a multi-class classification problem.\n",
        "\n",
        "model=Model(i,x) #Model func groups layers into an output object with the training features provided by us.\n",
        "#Give model description\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKxb8Kw9fprf"
      },
      "outputs": [],
      "source": [
        "#Compiling the model,\n",
        "#We use model.compile() func to compile our trained model\n",
        "#using parameters such as optimizer func, loss func, accuracy metrics.\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5VIrW4L-y7W",
        "outputId": "3a6b0961-401d-4292-9b9d-3ca2cb08a725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 326s 208ms/step - loss: 1.4737 - accuracy: 0.5038 - val_loss: 1.3051 - val_accuracy: 0.5467\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 326s 208ms/step - loss: 1.0527 - accuracy: 0.6321 - val_loss: 1.0421 - val_accuracy: 0.6399\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 326s 208ms/step - loss: 0.8582 - accuracy: 0.7045 - val_loss: 1.0462 - val_accuracy: 0.6409\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 307s 197ms/step - loss: 0.7032 - accuracy: 0.7551 - val_loss: 0.9471 - val_accuracy: 0.6926\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 315s 201ms/step - loss: 0.5757 - accuracy: 0.8000 - val_loss: 1.0445 - val_accuracy: 0.6674\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 323s 207ms/step - loss: 0.4633 - accuracy: 0.8412 - val_loss: 1.2384 - val_accuracy: 0.6366\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 328s 210ms/step - loss: 0.3684 - accuracy: 0.8741 - val_loss: 1.0636 - val_accuracy: 0.6982\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 336s 215ms/step - loss: 0.3124 - accuracy: 0.8945 - val_loss: 1.2221 - val_accuracy: 0.6787\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 327s 210ms/step - loss: 0.2655 - accuracy: 0.9110 - val_loss: 1.2255 - val_accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 325s 208ms/step - loss: 0.2267 - accuracy: 0.9240 - val_loss: 1.1223 - val_accuracy: 0.7010\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 330s 211ms/step - loss: 0.2010 - accuracy: 0.9337 - val_loss: 1.3746 - val_accuracy: 0.6635\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 321s 206ms/step - loss: 0.1737 - accuracy: 0.9429 - val_loss: 1.4185 - val_accuracy: 0.6976\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 344s 220ms/step - loss: 0.1659 - accuracy: 0.9454 - val_loss: 1.4625 - val_accuracy: 0.6872\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 346s 221ms/step - loss: 0.1509 - accuracy: 0.9507 - val_loss: 1.3185 - val_accuracy: 0.7118\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 367s 235ms/step - loss: 0.1380 - accuracy: 0.9558 - val_loss: 1.2760 - val_accuracy: 0.7189\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 365s 234ms/step - loss: 0.1293 - accuracy: 0.9574 - val_loss: 1.3751 - val_accuracy: 0.7072\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 355s 227ms/step - loss: 0.1119 - accuracy: 0.9627 - val_loss: 1.3858 - val_accuracy: 0.7168\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 356s 228ms/step - loss: 0.1150 - accuracy: 0.9634 - val_loss: 1.4602 - val_accuracy: 0.7047\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 333s 213ms/step - loss: 0.1081 - accuracy: 0.9647 - val_loss: 1.3641 - val_accuracy: 0.6984\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 310s 199ms/step - loss: 0.0972 - accuracy: 0.9690 - val_loss: 1.5128 - val_accuracy: 0.7073\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 310s 198ms/step - loss: 0.0909 - accuracy: 0.9703 - val_loss: 1.4291 - val_accuracy: 0.7187\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 302s 193ms/step - loss: 0.0879 - accuracy: 0.9720 - val_loss: 1.3404 - val_accuracy: 0.7064\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 304s 194ms/step - loss: 0.0862 - accuracy: 0.9720 - val_loss: 1.2871 - val_accuracy: 0.7179\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 307s 197ms/step - loss: 0.0837 - accuracy: 0.9725 - val_loss: 1.4794 - val_accuracy: 0.6956\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 318s 203ms/step - loss: 0.0757 - accuracy: 0.9756 - val_loss: 1.3040 - val_accuracy: 0.7143\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 317s 203ms/step - loss: 0.0742 - accuracy: 0.9755 - val_loss: 1.4690 - val_accuracy: 0.7227\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 317s 203ms/step - loss: 0.0698 - accuracy: 0.9778 - val_loss: 1.6734 - val_accuracy: 0.6510\n",
            "Epoch 28/50\n",
            " 810/1563 [==============>...............] - ETA: 2:26 - loss: 0.0520 - accuracy: 0.9829"
          ]
        }
      ],
      "source": [
        "#Lets fit our model using model.fit() and train them with training data,\n",
        "#vallidation split data and testing data till 50 epochs \n",
        "#(epoch is the no of times the model will cycle through the data)\n",
        "r = model.fit(trainX,trainY,validation_data=(testX,testY),epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VamCvlcdLKAp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot accuracy per iteration for epoch vs loss\n",
        "plt.plot(r.history['accuracy'], label='acc', color='red')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc', color='green')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMHJAWdZw_3I"
      },
      "outputs": [],
      "source": [
        "#label mapping\n",
        "labels=\n",
        "\n",
        "#Select the image from our test dataset\n",
        "image_number=0\n",
        "# select the image from our test dataset\n",
        "image_number = 0\n",
        " \n",
        "# display the image\n",
        "plt.imshow(testX[image_number])\n",
        " \n",
        "# load the image in an array\n",
        "n = np.array(testX[image_number])\n",
        " \n",
        "# reshape it\n",
        "p = n.reshape(1, 32, 32, 3)\n",
        " \n",
        "# pass in the network for prediction and\n",
        "# save the predicted label\n",
        "predicted_label = labels[model.predict(p).argmax()]\n",
        " \n",
        "# load the original label\n",
        "original_label = labels[testY[image_number]]\n",
        " \n",
        "# display the result\n",
        "print(\"Original label is {} and predicted label is {}\".format(\n",
        "    original_label, predicted_label))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}